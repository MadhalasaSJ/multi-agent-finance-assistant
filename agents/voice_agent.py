import sys
import whisper
import platform
import os

# Add root path to import orchestrator
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from orchestrator.orchestrator import Orchestrator

class VoiceAgent:
    def __init__(self):
        print("ğŸ”ˆ Initializing Whisper STT and optional TTS...")

        # Use a lightweight model for Streamlit Cloud
        self.model = whisper.load_model("tiny")

        # TTS enabled only for local (Windows/macOS)
        self.enable_tts = platform.system() in ["Windows", "Darwin"]
        if self.enable_tts:
            import pyttsx3
            self.engine = pyttsx3.init()

        # Load orchestrator
        self.orchestrator = Orchestrator()

    def speech_to_text(self, audio_file):
        print("ğŸ“ Transcribing audio...")
        try:
            result = self.model.transcribe(audio_file)
            print("ğŸ§¾ Whisper result:", result)
            return result.get("text", "").strip()
        except Exception as e:
            print(f"âŒ Transcription error: {e}")
            return ""

    def text_to_speech(self, text, out_file="output.wav"):
        if not self.enable_tts:
            print("ğŸ”‡ TTS disabled in Streamlit Cloud")
            return

        print("ğŸ—£ï¸ Saving speech to file...")
        try:
            self.engine.save_to_file(text, out_file)
            self.engine.runAndWait()
        except RuntimeError:
            print("âš ï¸ pyttsx3 event loop conflict â€” skipping playback.")

    def handle_audio_query(self, audio_file):
        """ğŸ‘‚ Record â†’ ğŸ§  Understand â†’ ğŸ’¬ Speak"""
        query = self.speech_to_text(audio_file)
        print("ğŸ‘‚ You said:", query)

        if query.strip():
            response = self.orchestrator.handle(query)
            self.text_to_speech(response)
            return query, response
        else:
            return "", "âš ï¸ No valid speech detected."
